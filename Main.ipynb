{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Music recommendation using graphs</h1>\n",
    "<h2>MLNS PROJECT</h2>\n",
    "<h3>Coded by Chloé Daems, Amir Mahmoudi and Anne-Claire Laisney</h3>\n",
    "</center>\n",
    "\n",
    "This is the main notebook to create a benchmark of graph based music recommendation systems inspired by the *Katarya, R., Verma, O.P. Efficient music recommender system using context graph and particle swarm. Multimed Tools Appl 77, 2673–2687 (2018).* [paper](URL 'https://link.springer.com/article/10.1007/s11042-017-4447-x'), using data from the user.getRecentTracks of the [Last.fm](URL 'https://www.last.fm/api/show/user.getRecentTracks') API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.sparse import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "user_id_profile = pd.read_csv('lastfm-dataset-1K/userid-profile.tsv', sep = '\\t')\n",
    "if not exists('lastfm-dataset-1K/user_id_logs_v2.tsv'):\n",
    "    logs_columns = ['userid', 'timestamp', 'artist-id', 'artist-name', 'track-id', 'track-name']\n",
    "    user_id_logs = pd.read_csv('lastfm-dataset-1K/userid-logs.tsv', sep = '\\t', header = None, names =  logs_columns )\n",
    "    user_id_logs = user_id_logs.dropna(subset=['track-name','artist-name', 'artist-id'])\n",
    "else : \n",
    "    user_id_logs = pd.read_csv('lastfm-dataset-1K/user_id_logs_v2.tsv',index_col=0)\n",
    "    user_id_logs = user_id_logs.dropna(subset=['track-name','artist-name', 'artist-id'])\n",
    "    \n",
    "#user_id_logs['timestamp'] = pd.to_datetime(user_id_logs['timestamp'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "user_id_logs['timestamp'] = pd.to_datetime(user_id_logs['timestamp'], format='%Y-%m-%d')# %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Aug 13, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000002</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Feb 24, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000003</td>\n",
       "      <td>m</td>\n",
       "      <td>22.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oct 30, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000004</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 26, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000005</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Jun 29, 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #id gender   age        country    registered\n",
       "0  user_000001      m   NaN          Japan  Aug 13, 2006\n",
       "1  user_000002      f   NaN           Peru  Feb 24, 2006\n",
       "2  user_000003      m  22.0  United States  Oct 30, 2005\n",
       "3  user_000004      f   NaN            NaN  Apr 26, 2006\n",
       "4  user_000005      m   NaN       Bulgaria  Jun 29, 2006"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>track-id</th>\n",
       "      <th>track-name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 23:08:57+00:00</td>\n",
       "      <td>f1b1cf71-bd35-4e99-8624-24a6e15f133a</td>\n",
       "      <td>Deep Dish</td>\n",
       "      <td>7369ec4f-b377-5683-86bd-f02897317103</td>\n",
       "      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:54:10+00:00</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>8a0799b1-2f64-5e7b-9436-2228c9d65637</td>\n",
       "      <td>Composition 0919 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:52:04+00:00</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>44da66dc-6a34-54de-a4d9-686bc38ede0f</td>\n",
       "      <td>Mc2 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:52+00:00</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>e625acbe-1360-528d-8afe-4ad88424e0c0</td>\n",
       "      <td>Hibari (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:11+00:00</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>fa332ed7-b701-5669-9e8e-0961658cdb43</td>\n",
       "      <td>Mc1 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid                 timestamp  \\\n",
       "0  user_000001 2009-05-04 23:08:57+00:00   \n",
       "1  user_000001 2009-05-04 13:54:10+00:00   \n",
       "2  user_000001 2009-05-04 13:52:04+00:00   \n",
       "3  user_000001 2009-05-04 13:42:52+00:00   \n",
       "4  user_000001 2009-05-04 13:42:11+00:00   \n",
       "\n",
       "                              artist-id artist-name  \\\n",
       "0  f1b1cf71-bd35-4e99-8624-24a6e15f133a   Deep Dish   \n",
       "1  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8        坂本龍一   \n",
       "2  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8        坂本龍一   \n",
       "3  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8        坂本龍一   \n",
       "4  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8        坂本龍一   \n",
       "\n",
       "                               track-id  \\\n",
       "0  7369ec4f-b377-5683-86bd-f02897317103   \n",
       "1  8a0799b1-2f64-5e7b-9436-2228c9d65637   \n",
       "2  44da66dc-6a34-54de-a4d9-686bc38ede0f   \n",
       "3  e625acbe-1360-528d-8afe-4ad88424e0c0   \n",
       "4  fa332ed7-b701-5669-9e8e-0961658cdb43   \n",
       "\n",
       "                                   track-name  \n",
       "0  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007  \n",
       "1           Composition 0919 (Live_2009_4_15)  \n",
       "2                        Mc2 (Live_2009_4_15)  \n",
       "3                     Hibari (Live_2009_4_15)  \n",
       "4                        Mc1 (Live_2009_4_15)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are too many track-ids missing, we are going to recreate them using the uuid library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really long : 40 min\n",
    "import tqdm\n",
    "import uuid\n",
    "if not exists('lastfm-dataset-1K/user_id_logs_v2.tsv'):\n",
    "    for idx, row in tqdm.tqdm(user_id_logs.iterrows()):\n",
    "        row['track-id'] = uuid.uuid5(uuid.NAMESPACE_DNS, row['artist-name'] + \",\" + row['track-name'])\n",
    "        row['artist-id'] = uuid.uuid5(uuid.NAMESPACE_DNS, str(row['artist-name']))\n",
    "    #We save the file\n",
    "    user_id_logs.to_csv('lastfm-dataset-1K/user_id_logs_v2.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We create a train and test set**\n",
    "\n",
    "In the test set, we would have only the last month of listening for each users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_user_id_logs = user_id_logs[user_id_logs['timestamp'] > datetime.datetime(2009, 4, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "    train_user_id_logs = user_id_logs[user_id_logs['timestamp'] < datetime.datetime(2009, 4, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "except:\n",
    "    test_user_id_logs = user_id_logs[user_id_logs['timestamp'] > datetime.datetime(2009, 4, 4)]\n",
    "    train_user_id_logs = user_id_logs[user_id_logs['timestamp'] < datetime.datetime(2009, 4, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : ((17815729, 6) and test shape : ((682269, 6))\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape : ({train_user_id_logs.shape} and test shape : ({test_user_id_logs.shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    val_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] > datetime.datetime(2009, 3, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "    train_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] < datetime.datetime(2009, 3, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "except:\n",
    "    val_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] > datetime.datetime(2009, 3, 4)]\n",
    "    train_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] < datetime.datetime(2009, 3, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : ((17217876, 6) and val shape : ((597852, 6))\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape : ({train_user_id_logs.shape} and val shape : ({val_user_id_logs.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's only take the n most listened songs of each users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_top(df_logs,df_profile, n_top):\n",
    "    new_df = pd.DataFrame(columns = ['track-name','artist-name'], dtype= np.str)\n",
    "    for user_id in df_profile.values:\n",
    "        test = df_logs[df_logs['userid']== user_id]\n",
    "        try:\n",
    "            test['count'] = test.groupby(['track-id'])[['track-id']].transform(lambda x: x.count())['track-id']\n",
    "            test = test.sort_values(by = 'count', ascending = False)\n",
    "            test = test.drop('timestamp', axis = 1)\n",
    "            test = test.drop_duplicates()\n",
    "            new_df = pd.concat([new_df, test[:n_top]], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "        clear_output(wait = True)\n",
    "        print(\"Just finished for\",user_id)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>userid</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Basanov &amp; Vidis ‘Test’</td>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "      <td>7434fb0f-1245-5a58-b343-cca4d0e2c107</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Song</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>4562ff4f-b619-5557-8600-87f6d0d9f348</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Build A Home</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>dcf825de-85a9-5b53-9d2b-a9d574b57470</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track-name              artist-name       userid  \\\n",
       "0                         Music                Cornelius  user_000001   \n",
       "1                           Gum                Cornelius  user_000001   \n",
       "2  Mario Basanov & Vidis ‘Test’          Gilles Peterson  user_000001   \n",
       "3                    Child Song  The Cinematic Orchestra  user_000001   \n",
       "4               To Build A Home  The Cinematic Orchestra  user_000001   \n",
       "\n",
       "                              artist-id                              track-id  \\\n",
       "0  df765d93-621c-437f-99fe-fda9e135f89a  52bef5e2-17b6-5742-b846-09a6b750e857   \n",
       "1  df765d93-621c-437f-99fe-fda9e135f89a  bb9a7981-016d-596e-b17f-ba07a346d2d4   \n",
       "2  4c4e3121-4d12-4f7a-a77c-5becd849fb3c  7434fb0f-1245-5a58-b343-cca4d0e2c107   \n",
       "3  7c158ea8-c0aa-410e-bdc1-20bba9759577  4562ff4f-b619-5557-8600-87f6d0d9f348   \n",
       "4  7c158ea8-c0aa-410e-bdc1-20bba9759577  dcf825de-85a9-5b53-9d2b-a9d574b57470   \n",
       "\n",
       "   count  \n",
       "0   70.0  \n",
       "1   63.0  \n",
       "2   50.0  \n",
       "3   44.0  \n",
       "4   41.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('./saved_data/train_user_top_logs.tsv'):\n",
    "    train_user_top_logs = get_only_top(train_user_id_logs,user_id_profile['#id'], n_top = 50)\n",
    "    train_user_top_logs = train_user_top_logs.nlargest(10000,'count')\n",
    "    train_user_top_logs.to_csv('./saved_data/train_user_top_logs.tsv')\n",
    "\n",
    "else : \n",
    "    train_user_top_logs = pd.read_csv('./saved_data/train_user_top_logs.tsv', index_col=0)\n",
    "\n",
    "train_user_top_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the dataset into a bipartite graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Basanov &amp; Vidis ‘Test’</td>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "      <td>7434fb0f-1245-5a58-b343-cca4d0e2c107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Song</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>4562ff4f-b619-5557-8600-87f6d0d9f348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Build A Home</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>dcf825de-85a9-5b53-9d2b-a9d574b57470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track-name              artist-name  \\\n",
       "0                         Music                Cornelius   \n",
       "1                           Gum                Cornelius   \n",
       "2  Mario Basanov & Vidis ‘Test’          Gilles Peterson   \n",
       "3                    Child Song  The Cinematic Orchestra   \n",
       "4               To Build A Home  The Cinematic Orchestra   \n",
       "\n",
       "                              artist-id                              track-id  \n",
       "0  df765d93-621c-437f-99fe-fda9e135f89a  52bef5e2-17b6-5742-b846-09a6b750e857  \n",
       "1  df765d93-621c-437f-99fe-fda9e135f89a  bb9a7981-016d-596e-b17f-ba07a346d2d4  \n",
       "2  4c4e3121-4d12-4f7a-a77c-5becd849fb3c  7434fb0f-1245-5a58-b343-cca4d0e2c107  \n",
       "3  7c158ea8-c0aa-410e-bdc1-20bba9759577  4562ff4f-b619-5557-8600-87f6d0d9f348  \n",
       "4  7c158ea8-c0aa-410e-bdc1-20bba9759577  dcf825de-85a9-5b53-9d2b-a9d574b57470  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('./saved_data/track_df.tsv'):\n",
    "    track_df = train_user_top_logs.copy()\n",
    "    track_df.drop(['count', 'userid'], axis = 1, inplace=True)\n",
    "    track_df.drop_duplicates('track-id', inplace=True)\n",
    "    track_df.reset_index(drop=True, inplace=True)\n",
    "    track_df.to_csv('./saved_data/track_df.tsv')\n",
    "else : \n",
    "    track_df = pd.read_csv('./saved_data/track_df.tsv', index_col=0)\n",
    "\n",
    "track_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist-name</th>\n",
       "      <th>artist-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radiohead</td>\n",
       "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Hundred Birds</td>\n",
       "      <td>f5341587-6c20-4e0f-bdfd-62b2122825f2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist-name                             artist-id\n",
       "0                Cornelius  df765d93-621c-437f-99fe-fda9e135f89a\n",
       "1          Gilles Peterson  4c4e3121-4d12-4f7a-a77c-5becd849fb3c\n",
       "2  The Cinematic Orchestra  7c158ea8-c0aa-410e-bdc1-20bba9759577\n",
       "3                Radiohead  a74b1b7f-71a5-4011-9441-d0b5e4122711\n",
       "4          A Hundred Birds  f5341587-6c20-4e0f-bdfd-62b2122825f2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('./saved_data/artists_df.tsv'):\n",
    "    artist_df = train_user_top_logs.copy()\n",
    "    artist_df.drop(['count', 'userid', 'track-name', 'track-id'], axis = 1, inplace=True)\n",
    "    artist_df.drop_duplicates('artist-id', inplace=True)\n",
    "    artist_df.reset_index(drop=True, inplace=True)\n",
    "    artist_df.to_csv('./saved_data/artists_df.tsv')\n",
    "else : \n",
    "    artist_df = pd.read_csv('./saved_data/artists_df.tsv', index_col=0)\n",
    "\n",
    "artist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "#We transform the train set into a bipartite graph\n",
    "G= nx.Graph()\n",
    "edges_1 = np.array(train_user_top_logs[['userid', 'track-id','count']].values)\n",
    "edges_2 = np.array(train_user_top_logs[['artist-id', 'track-id']].values)\n",
    "G.add_nodes_from(user_id_profile['#id'], bipartite=0)\n",
    "G.add_nodes_from(track_df['track-id'], bipartite=1)\n",
    "G.add_nodes_from(artist_df['artist-id'], bipartite=2)\n",
    "     \n",
    "G.add_weighted_edges_from(edges_1)\n",
    "#weighted graph\n",
    "G.add_edges_from(edges_2)\n",
    "#save the edges\n",
    "nx.write_gml(G, \"saved_data/graph_user_tracks_train.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we transform the validation data set in a bipartite graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished for user_001000\n"
     ]
    }
   ],
   "source": [
    "#We transform the val set into a bipartite graph\n",
    "\n",
    "#First we select only the music tracks that are in the train set\n",
    "val_user_id_logs = val_user_id_logs[val_user_id_logs['track-id'].isin(track_df['track-id'])]\n",
    "val_user_id_logs_top = get_only_top(val_user_id_logs,user_id_profile['#id'], n_top = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we create the graph\n",
    "\n",
    "G_val = nx.Graph()\n",
    "edges_1 = np.array(val_user_id_logs_top[['userid', 'track-id','count']].values)\n",
    "edges_2 = np.array(train_user_top_logs[['artist-id', 'track-id']].values)\n",
    "\n",
    "G_val.add_nodes_from(user_id_profile['#id'], bipartite=0)\n",
    "G_val.add_nodes_from(track_df['track-id'], bipartite=1)\n",
    "G_val.add_nodes_from(artist_df['artist-id'], bipartite=2)\n",
    "     \n",
    "G_val.add_weighted_edges_from(edges_1)\n",
    "\n",
    "#weighted graph\n",
    "G_val.add_edges_from(edges_2)\n",
    "#save the graph\n",
    "nx.write_gml(G_val, \"saved_data/graph_user_tracks_val.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished for user_001000\n"
     ]
    }
   ],
   "source": [
    "#We transform the val set into a bipartite graph\n",
    "\n",
    "#First we select only the music tracks that are in the train set\n",
    "test_user_id_logs = val_user_id_logs[val_user_id_logs['track-id'].isin(track_df['track-id'])]\n",
    "test_user_id_logs_top = get_only_top(val_user_id_logs,user_id_profile['#id'], n_top = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we create the graph\n",
    "\n",
    "G_test_gt = nx.Graph()\n",
    "edges_1 = np.array(test_user_id_logs_top[['userid', 'track-id','count']].values)\n",
    "edges_2 = np.array(train_user_top_logs[['artist-id', 'track-id']].values)\n",
    "\n",
    "G_test_gt.add_nodes_from(user_id_profile['#id'], bipartite=0)\n",
    "G_test_gt.add_nodes_from(track_df['track-id'], bipartite=1)\n",
    "G_test_gt.add_nodes_from(artist_df['artist-id'], bipartite=2)\n",
    "     \n",
    "G_test_gt.add_weighted_edges_from(edges_1)\n",
    "\n",
    "#weighted graph\n",
    "G_test_gt.add_edges_from(edges_2)\n",
    "#save the graph\n",
    "nx.write_gml(G_test_gt, \"saved_data/graph_user_tracks_test_groundtruth.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the methods\n",
    "Pearson coefficient, Bellman ford algorithm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_G  = nx.read_gml(\"saved_data/graph_user_tracks_train.gml\")\n",
    "val_G  = nx.read_gml(\"saved_data/graph_user_tracks_val.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try the methods from TP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised link prediction\n",
    "\n",
    "ALL THE METHODS ARE TO BE PUT IN A UTIL.PY FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachement(graph, edges=train_G.edges()):\n",
    "    PA = {}\n",
    "    \n",
    "    for edge in edges:\n",
    "        PA[edge] = graph.degree(edge[0]) * graph.degree(edge[1])\n",
    "        \n",
    "    return PA\n",
    "    \n",
    "pa = preferential_attachement(train_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(graph, edges=train_G.edges()):\n",
    "    Jaccard = {}\n",
    "    # Compute Jaccard metric for each non_edge of the graph\n",
    "    \n",
    "    for edge in edges: \n",
    "        inter_size = len(list(nx.common_neighbors(graph, edge[0], edge[1])))\n",
    "        union_size = len(set(graph[edge[0]]) | set(graph[edge[1]]))\n",
    "\n",
    "        if union_size != 0:\n",
    "            Jaccard[edge] = inter_size / union_size\n",
    "        else : \n",
    "            Jaccard[edge] = 0\n",
    "\n",
    "    \n",
    "    return Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamicAdar(graph, edges=train_G.edges()):\n",
    "    AdamicAdar = {}\n",
    "    \n",
    "    for edge in edges: \n",
    "        inter_list = nx.common_neighbors(graph, edge[0], edge[1])\n",
    "        AdamicAdar[edge] = sum( [1/np.log(graph.degree(node)) for node in inter_list] )\n",
    "    \n",
    "    return AdamicAdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(('88ff31ff-07d3-5909-b8d4-942377de3c04', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 3000), (('1f5924d3-c1b3-5d5e-9ca4-4e062e9019be', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 2400), (('90744886-c2db-590b-bfb6-50d409cddabf', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 2040), (('ca1bbb67-f89e-5043-889c-e6f46add205f', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 1920), (('d8da1e04-5582-561e-8b81-41b67ee46460', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 1800), (('4acc0486-b446-5428-87b4-1e7dd46d070d', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 1800), (('af21c041-7bb4-5fdc-abbd-efd9b40df73c', '83d91898-7763-47d7-b03b-b92132375c47'), 1674), (('ef283a65-240f-58b5-a127-4a2b44c617aa', '03ad1736-b7c9-412a-b442-82536d63a5c4'), 1638), (('0e938086-1f83-5242-944b-7315de233b57', '0039c7ae-e1a7-4a7d-9b49-0cbc716821a6'), 1608), (('59671b3e-76a0-5da7-af83-d593dc187dd5', 'a74b1b7f-71a5-4011-9441-d0b5e4122711'), 1560)])\n"
     ]
    }
   ],
   "source": [
    "def predict_edges(metric, k):\n",
    "    \n",
    "    # Shuffle randomly entries of dictionnary \n",
    "    l = list(metric.items())\n",
    "    np.random.seed(10) # fix random seed to obtain same random shuffling when repeating experiment\n",
    "    np.random.shuffle(l)\n",
    "    metric = dict(l)\n",
    "\n",
    "    # Retrieve top k value \n",
    "    metric = dict(sorted(metric.items(), key=lambda x:x[1], reverse=True)[:k])\n",
    "    print(metric.items())\n",
    "\n",
    "predict_edges(pa, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "#1 hour to compute NOT TRIED -- (but the result in the state of the art is bad)\n",
    "def evaluation(G_train, G_val):\n",
    "    R = G_val.copy()\n",
    "    R.remove_edges_from(e for e in G_val.edges if e in G_train.edges)\n",
    "    gt = R.edges\n",
    "    k = len(gt)\n",
    "    print(k)\n",
    "    print(\"Starting predictions\")\n",
    "    # --- Apply each method defined above and calculate its accuracy ---\n",
    "    methods = ['Jaccard', 'AdamicAdar', 'preferential_attachement']\n",
    "    \n",
    "    # For each method, compute the similarity scores between all non-edges\n",
    "    # Predict k node pairs with highest score \n",
    "    # Compute accuracy wrt edges actually removed \n",
    "    for method in methods: \n",
    "        res = eval(method)(G_train, nx.non_edges(G_train))\n",
    "        print(\"predicting 4 real \")\n",
    "        pred = sorted(res.items(), key = lambda x:x[1], reverse=True)[:k]\n",
    "        print(\"I finished predicting\")\n",
    "        pred = [el[0] for el in pred]\n",
    "        #print('pred', pred)\n",
    "        #print('gt',gt)\n",
    "        accuracy = len(set(pred).intersection(set(gt))) / k\n",
    "        print(method, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The graph is too big to be used for training and validation\n",
    "# We can remove the low degree nodes\n",
    "def remove_low_degree_nodes(train_graph, val_graph):\n",
    "    t_graph, v_graph = train_graph.copy(), val_graph.copy()\n",
    "    to_be_removed = [x for  x, d in t_graph.nodes(data=True) if (t_graph.degree(x) <= 3 and d['bipartite'] != 2)]\n",
    "    print(len(to_be_removed))\n",
    "    t_graph.remove_nodes_from(to_be_removed)\n",
    "    v_graph.remove_nodes_from(to_be_removed)\n",
    "    return t_graph, v_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove artist with no more edges\n",
    "def remove_low_artists(train_graph, val_graph):\n",
    "    t_graph, v_graph = train_graph.copy(), val_graph.copy()\n",
    "    to_be_removed = [x for  x, d in t_graph.nodes(data=True) if (t_graph.degree(x) ==0 and d['bipartite'] == 2)]\n",
    "    t_graph.remove_nodes_from(to_be_removed)\n",
    "    v_graph.remove_nodes_from(to_be_removed)\n",
    "    return t_graph, v_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11905, 11905)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_G,val_G = remove_low_degree_nodes(train_G,val_G)\n",
    "len(train_G.nodes),len(val_G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3757, 3757)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_G,val_G = remove_low_artists(train_G,val_G)\n",
    "len(train_G.nodes),len(val_G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19162\n",
      "Starting predictions\n",
      "predicting 4 real \n",
      "I finished predicting\n",
      "Jaccard 0.0\n",
      "predicting 4 real \n",
      "I finished predicting\n",
      "AdamicAdar 0.0\n",
      "predicting 4 real \n",
      "I finished predicting\n",
      "preferential_attachement 0.0036008767352050932\n"
     ]
    }
   ],
   "source": [
    "evaluation(train_G, val_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervized link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(graph, samples):\n",
    "    \"\"\"\n",
    "    Creates a feature vector for each edge of the graph contained in samples \n",
    "    \"\"\"\n",
    "    feature_vector = []\n",
    "    \n",
    "    # --- Extract manually diverse features relative to each edge contained in samples --- \n",
    "    # Fill in the blanks\n",
    "\n",
    "    # Degree Centrality measure\n",
    "    deg_centrality = nx.degree_centrality(graph)\n",
    "    \n",
    "    # Betweeness centrality measure\n",
    "    betweeness_centrality = nx.betweenness_centrality(graph)\n",
    "\n",
    "    for edge in tqdm(samples):\n",
    "        source_node, target_node = edge[0], edge[1]\n",
    "\n",
    "        # Degree Centrality\n",
    "        source_degree_centrality = deg_centrality[source_node]\n",
    "        target_degree_centrality = deg_centrality[target_node]\n",
    "        \n",
    "        # Betweeness centrality measure \n",
    "        diff_bt = betweeness_centrality[target_node] - betweeness_centrality[source_node]\n",
    "\n",
    "        # Preferential Attachement \n",
    "        pref_attach = list(nx.preferential_attachment(graph, [(source_node, target_node)]))[0][2]\n",
    "\n",
    "        # AdamicAdar\n",
    "        aai = list(nx.adamic_adar_index(graph, [(source_node, target_node)]))[0][2]\n",
    "\n",
    "        # Jaccard\n",
    "        jacard_coeff = list(nx.jaccard_coefficient(graph, [(source_node, target_node)]))[0][2]\n",
    "        \n",
    "        # Create edge feature vector with all metric computed above\n",
    "        feature_vector.append(np.array([source_degree_centrality, target_degree_centrality, \n",
    "                                        diff_bt, pref_attach, aai, jacard_coeff]) ) \n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(graph):\n",
    "    pos_sample=list(graph.edges)\n",
    "    neg_sample=list(nx.non_edges(graph))\n",
    "    labels = [1 for _ in pos_sample] + [0 for _ in neg_sample]\n",
    "    features=pos_sample+neg_sample\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets try with only detecting for non edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_edges_bipartite(G):\n",
    "    top_nodes = set(n for n,d in G.nodes(data=True) if d['bipartite']==0)\n",
    "    low_nodes = set(n for n,d in G.nodes(data=True) if d['bipartite']==1)\n",
    "    adj_matrix = bipartite.biadjacency_matrix(G, row_order=top_nodes, column_order=low_nodes)\n",
    "\n",
    "    negative_edges = []\n",
    "    top = list(top_nodes)\n",
    "    low = list(low_nodes)\n",
    "    for i in tqdm(range(len(top_nodes))):\n",
    "        for j in range(len(low_nodes)):\n",
    "            if adj_matrix[i,j]==0:\n",
    "                negative_edges.append([top[i],low[j]])\n",
    "    return negative_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [00:49<00:00, 19.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "train_neg_edges = get_neg_edges_bipartite(train_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_values(G, edges):\n",
    "    all_positive_edges = G.edges()\n",
    "    output = []\n",
    "    for edge in edges:\n",
    "        if(edge in all_positive_edges): \n",
    "            #output.append(G.edges[edge[0],edge[1]]['weight'])\n",
    "            output.append(1)  \n",
    "        else:\n",
    "            output.append(0)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(G, edges):\n",
    "    all_positive_edges = G.edges()\n",
    "    all_neg_edges=nx.non_edges(G)\n",
    "    all_edges = all_positive_edges + all_neg_edges\n",
    "    output=[1 for i in all_positive_edges ] + [0 for i in all_neg_edges ]\n",
    "   \n",
    "    return output,all_positive_edges,all_neg_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19162"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_links = get_edges_values(val_G, train_neg_edges)\n",
    "new_links.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2065151/2065151 [02:09<00:00, 15903.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Create feature vector for all edges in training set and test set ---\n",
    "train_features = feature_extractor(train_G, train_neg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_features, train_labels):\n",
    "    \"\"\"\n",
    "    Downstream ML task using edge embeddings to classify them \n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Build the model and train it ---\n",
    "    # Fill in the blanks\n",
    "    clf = RandomForestClassifier(random_state= 1999)\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    #compute accuracy\n",
    "    train_preds=clf.predict(train_features)\n",
    "\n",
    "    print(collections.Counter(np.array(train_preds)))\n",
    "    acc=accuracy_score(train_labels,train_preds)\n",
    "    recall=recall_score(train_labels,train_preds)\n",
    "    precision=precision_score(train_labels,train_preds)\n",
    "\n",
    "    print('Accuracy:',acc, 'Recall:',recall, 'Precision:',precision)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2055024, 1: 10127})\n",
      "Accuracy: 0.9954274530046471 Recall: 0.5178478238179731 Precision: 0.9798558309469735\n"
     ]
    }
   ],
   "source": [
    "RF_model = train(train_features, new_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>userid</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Basanov &amp; Vidis ‘Test’</td>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "      <td>7434fb0f-1245-5a58-b343-cca4d0e2c107</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Song</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>4562ff4f-b619-5557-8600-87f6d0d9f348</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Build A Home</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>dcf825de-85a9-5b53-9d2b-a9d574b57470</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125862</th>\n",
       "      <td>How To Disappear Completely</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
       "      <td>ccad68b7-c5ad-4f29-b169-2531fbf53f63</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125863</th>\n",
       "      <td>Everything In Its Right Place</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
       "      <td>60bd9d53-01ff-4562-8058-eb44b3940317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125864</th>\n",
       "      <td>Under The Blacklight</td>\n",
       "      <td>Rilo Kiley</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>eaf6a7ca-105d-4a94-ba02-8c3e4040319a</td>\n",
       "      <td>b912987f-8a21-4c7b-8412-f70ccd6dcd4d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125865</th>\n",
       "      <td>Dreamworld</td>\n",
       "      <td>Rilo Kiley</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>eaf6a7ca-105d-4a94-ba02-8c3e4040319a</td>\n",
       "      <td>d1561c20-50c2-4a48-9f5d-a92572347ddc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125866</th>\n",
       "      <td>Give A Little Love</td>\n",
       "      <td>Rilo Kiley</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>eaf6a7ca-105d-4a94-ba02-8c3e4040319a</td>\n",
       "      <td>c2c88554-8e0b-4ab6-8375-e50ded590b08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125867 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           track-name              artist-name       userid  \\\n",
       "0                               Music                Cornelius  user_000001   \n",
       "1                                 Gum                Cornelius  user_000001   \n",
       "2        Mario Basanov & Vidis ‘Test’          Gilles Peterson  user_000001   \n",
       "3                          Child Song  The Cinematic Orchestra  user_000001   \n",
       "4                     To Build A Home  The Cinematic Orchestra  user_000001   \n",
       "...                               ...                      ...          ...   \n",
       "125862    How To Disappear Completely                Radiohead  user_001000   \n",
       "125863  Everything In Its Right Place                Radiohead  user_001000   \n",
       "125864           Under The Blacklight               Rilo Kiley  user_001000   \n",
       "125865                     Dreamworld               Rilo Kiley  user_001000   \n",
       "125866             Give A Little Love               Rilo Kiley  user_001000   \n",
       "\n",
       "                                   artist-id  \\\n",
       "0       df765d93-621c-437f-99fe-fda9e135f89a   \n",
       "1       df765d93-621c-437f-99fe-fda9e135f89a   \n",
       "2       4c4e3121-4d12-4f7a-a77c-5becd849fb3c   \n",
       "3       7c158ea8-c0aa-410e-bdc1-20bba9759577   \n",
       "4       7c158ea8-c0aa-410e-bdc1-20bba9759577   \n",
       "...                                      ...   \n",
       "125862  a74b1b7f-71a5-4011-9441-d0b5e4122711   \n",
       "125863  a74b1b7f-71a5-4011-9441-d0b5e4122711   \n",
       "125864  eaf6a7ca-105d-4a94-ba02-8c3e4040319a   \n",
       "125865  eaf6a7ca-105d-4a94-ba02-8c3e4040319a   \n",
       "125866  eaf6a7ca-105d-4a94-ba02-8c3e4040319a   \n",
       "\n",
       "                                    track-id  count  \n",
       "0       52bef5e2-17b6-5742-b846-09a6b750e857   70.0  \n",
       "1       bb9a7981-016d-596e-b17f-ba07a346d2d4   63.0  \n",
       "2       7434fb0f-1245-5a58-b343-cca4d0e2c107   50.0  \n",
       "3       4562ff4f-b619-5557-8600-87f6d0d9f348   44.0  \n",
       "4       dcf825de-85a9-5b53-9d2b-a9d574b57470   41.0  \n",
       "...                                      ...    ...  \n",
       "125862  ccad68b7-c5ad-4f29-b169-2531fbf53f63    1.0  \n",
       "125863  60bd9d53-01ff-4562-8058-eb44b3940317    1.0  \n",
       "125864  b912987f-8a21-4c7b-8412-f70ccd6dcd4d    1.0  \n",
       "125865  d1561c20-50c2-4a48-9f5d-a92572347ddc    1.0  \n",
       "125866  c2c88554-8e0b-4ab6-8375-e50ded590b08    1.0  \n",
       "\n",
       "[125867 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate the train and val sets summing the count for the same track and the same user\n",
    "new_val_user_id_logs_top = pd.concat([train_user_top_logs, val_user_id_logs_top], ignore_index=True)\n",
    "#sum count column for same track and same user\n",
    "new_val_user_id_logs_top.groupby(['userid', 'track-id']).sum('count')\n",
    "new_val_user_id_logs_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we create the graph\n",
    "\n",
    "G_test = nx.Graph()\n",
    "edges_1 = np.array(new_val_user_id_logs_top[['userid', 'track-id','count']].values)\n",
    "edges_2 = np.array(train_user_top_logs[['artist-id', 'track-id']].values)\n",
    "\n",
    "G_test.add_nodes_from(user_id_profile['#id'], bipartite=0)\n",
    "G_test.add_nodes_from(track_df['track-id'], bipartite=1)\n",
    "G_test.add_nodes_from(artist_df['artist-id'], bipartite=2)\n",
    "     \n",
    "G_test.add_weighted_edges_from(edges_1)\n",
    "\n",
    "#weighted graph\n",
    "G_test.add_edges_from(edges_2)\n",
    "#save the graph\n",
    "nx.write_gml(G_test, \"saved_data/graph_user_tracks_test.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Downstream ML task using edge embeddings to classify them \n",
    "    \"\"\"\n",
    "\n",
    "    #compute accuracy\n",
    "    test_preds=model.predict(test_features)\n",
    "\n",
    "    print(collections.Counter(np.array(test_preds)))\n",
    "    acc=accuracy_score(test_labels,test_preds)\n",
    "    recall=recall_score(test_labels,test_preds)\n",
    "    precision=precision_score(test_labels,test_preds)\n",
    "\n",
    "    print('Accuracy:',acc, 'Recall:',recall, 'Precision:',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test.remove_nodes_from([n for n in G_test.nodes() if n not in train_G.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [00:48<00:00, 19.89it/s]\n",
      "100%|██████████| 2045989/2045989 [04:04<00:00, 8380.44it/s] \n"
     ]
    }
   ],
   "source": [
    "test_neg_edges = get_neg_edges_bipartite(G_test)\n",
    "# --- Create feature vector for all edges in training set and test set ---\n",
    "test_features = feature_extractor(G_test, test_neg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = get_edges_values(G_test_gt, test_neg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2045989})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0 Recall: 0.0 Precision: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1999)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2028691, 1: 17298})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9915454090906647 Recall: 0.0 Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "predict(RF_model,test_features,test_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
