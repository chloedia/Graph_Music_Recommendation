{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Music recommendation using graphs</h1>\n",
    "<h2>MLNS PROJECT</h2>\n",
    "<h3>Coded by Chloé Daems, Amir Mahmoudi and Anne-Claire Laisney</h3>\n",
    "</center>\n",
    "\n",
    "This is the main notebook to create a benchmark of graph based music recommendation systems inspired by the *Katarya, R., Verma, O.P. Efficient music recommender system using context graph and particle swarm. Multimed Tools Appl 77, 2673–2687 (2018).* [paper](URL 'https://link.springer.com/article/10.1007/s11042-017-4447-x'), using data from the user.getRecentTracks of the [Last.fm](URL 'https://www.last.fm/api/show/user.getRecentTracks') API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.sparse import *\n",
    "from IPython.display import clear_output\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "#from scratch methods\n",
    "from dataframe_utils import *\n",
    "from graph_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the dataset**\n",
    "\n",
    "**Initially, There are too many track-ids missing, we are going to recreate them using the uuid library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "user_id_profile = pd.read_csv('lastfm-dataset-1K/userid-profile.tsv', sep = '\\t')\n",
    "user_id_logs = users('lastfm-dataset-1K/user_id_logs_v2.tsv') #all the process is done in the users function check dataframe_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Aug 13, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000002</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Feb 24, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000003</td>\n",
       "      <td>m</td>\n",
       "      <td>22.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oct 30, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000004</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 26, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000005</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Jun 29, 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #id gender   age        country    registered\n",
       "0  user_000001      m   NaN          Japan  Aug 13, 2006\n",
       "1  user_000002      f   NaN           Peru  Feb 24, 2006\n",
       "2  user_000003      m  22.0  United States  Oct 30, 2005\n",
       "3  user_000004      f   NaN            NaN  Apr 26, 2006\n",
       "4  user_000005      m   NaN       Bulgaria  Jun 29, 2006"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>track-id</th>\n",
       "      <th>track-name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 23:08:57</td>\n",
       "      <td>f1b1cf71-bd35-4e99-8624-24a6e15f133a</td>\n",
       "      <td>Deep Dish</td>\n",
       "      <td>7369ec4f-b377-5683-86bd-f02897317103</td>\n",
       "      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:54:10</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>8a0799b1-2f64-5e7b-9436-2228c9d65637</td>\n",
       "      <td>Composition 0919 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:52:04</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>44da66dc-6a34-54de-a4d9-686bc38ede0f</td>\n",
       "      <td>Mc2 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:52</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>e625acbe-1360-528d-8afe-4ad88424e0c0</td>\n",
       "      <td>Hibari (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:11</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>fa332ed7-b701-5669-9e8e-0961658cdb43</td>\n",
       "      <td>Mc1 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid           timestamp                             artist-id  \\\n",
       "0  user_000001 2009-05-04 23:08:57  f1b1cf71-bd35-4e99-8624-24a6e15f133a   \n",
       "1  user_000001 2009-05-04 13:54:10  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "2  user_000001 2009-05-04 13:52:04  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "3  user_000001 2009-05-04 13:42:52  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "4  user_000001 2009-05-04 13:42:11  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "\n",
       "  artist-name                              track-id  \\\n",
       "0   Deep Dish  7369ec4f-b377-5683-86bd-f02897317103   \n",
       "1        坂本龍一  8a0799b1-2f64-5e7b-9436-2228c9d65637   \n",
       "2        坂本龍一  44da66dc-6a34-54de-a4d9-686bc38ede0f   \n",
       "3        坂本龍一  e625acbe-1360-528d-8afe-4ad88424e0c0   \n",
       "4        坂本龍一  fa332ed7-b701-5669-9e8e-0961658cdb43   \n",
       "\n",
       "                                   track-name  \n",
       "0  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007  \n",
       "1           Composition 0919 (Live_2009_4_15)  \n",
       "2                        Mc2 (Live_2009_4_15)  \n",
       "3                     Hibari (Live_2009_4_15)  \n",
       "4                        Mc1 (Live_2009_4_15)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We create a train and test set**\n",
    "\n",
    "In the test set, we would have only the two last month of listening for each users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_user_id_logs = user_id_logs[user_id_logs['timestamp'] > datetime.datetime(2009, 3, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "    train_user_id_logs = user_id_logs[user_id_logs['timestamp'] < datetime.datetime(2009, 3, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "except:\n",
    "    test_user_id_logs = user_id_logs[user_id_logs['timestamp'] > datetime.datetime(2009, 3, 4)]\n",
    "    train_user_id_logs = user_id_logs[user_id_logs['timestamp'] < datetime.datetime(2009, 3, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : ((8519568, 6) and test shape : ((613400, 6))\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape : ({train_user_id_logs.shape} and test shape : ({test_user_id_logs.shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    val_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] > datetime.datetime(2009, 1, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "    train_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] < datetime.datetime(2009, 1, 4).replace(tzinfo=datetime.timezone.utc)]\n",
    "except:\n",
    "    val_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] > datetime.datetime(2009, 1, 4)]\n",
    "    train_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] < datetime.datetime(2009, 1, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : ((7975441, 6), val shape : ((544126, 6)) and test shape : ((613400, 6))\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape : ({train_user_id_logs.shape}, val shape : ({val_user_id_logs.shape}) and test shape : ({test_user_id_logs.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's only take the n most listened songs of each users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>userid</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43661</th>\n",
       "      <td>Jolene</td>\n",
       "      <td>Cake</td>\n",
       "      <td>user_000949</td>\n",
       "      <td>fa7b9055-3703-473a-8a09-adf2fe031a24</td>\n",
       "      <td>60f0bfa4-8da9-4840-b5fe-23c1fc470f34</td>\n",
       "      <td>1456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43662</th>\n",
       "      <td>Staring At The Sun</td>\n",
       "      <td>Tv On The Radio</td>\n",
       "      <td>user_000949</td>\n",
       "      <td>eb872766-98f6-453d-883f-2ae908a18315</td>\n",
       "      <td>64581a21-566d-4b24-99ae-c5f48b75e660</td>\n",
       "      <td>1409.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               track-name      artist-name       userid  \\\n",
       "43661              Jolene             Cake  user_000949   \n",
       "43662  Staring At The Sun  Tv On The Radio  user_000949   \n",
       "\n",
       "                                  artist-id  \\\n",
       "43661  fa7b9055-3703-473a-8a09-adf2fe031a24   \n",
       "43662  eb872766-98f6-453d-883f-2ae908a18315   \n",
       "\n",
       "                                   track-id   count  \n",
       "43661  60f0bfa4-8da9-4840-b5fe-23c1fc470f34  1456.0  \n",
       "43662  64581a21-566d-4b24-99ae-c5f48b75e660  1409.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('./saved_data/train_user_top_logs.tsv'):\n",
    "    train_user_top_logs = get_only_top(train_user_id_logs,user_id_profile['#id'], n_top = 50)\n",
    "    train_user_top_logs = train_user_top_logs.nlargest(10000,'count')\n",
    "    train_user_top_logs.to_csv('./saved_data/train_user_top_logs.tsv')\n",
    "\n",
    "else : \n",
    "    train_user_top_logs = pd.read_csv('./saved_data/train_user_top_logs.tsv', index_col=0)\n",
    "\n",
    "train_user_top_logs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the dataset into a bipartite graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track-name artist-name                             artist-id  \\\n",
       "0      Music   Cornelius  df765d93-621c-437f-99fe-fda9e135f89a   \n",
       "1        Gum   Cornelius  df765d93-621c-437f-99fe-fda9e135f89a   \n",
       "\n",
       "                               track-id  \n",
       "0  52bef5e2-17b6-5742-b846-09a6b750e857  \n",
       "1  bb9a7981-016d-596e-b17f-ba07a346d2d4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_df,artist_df=bipartite_graph('./saved_data/track_df.tsv','./saved_data/artists_df.tsv',train_user_top_logs)\n",
    "track_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist-name</th>\n",
       "      <th>artist-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist-name                             artist-id\n",
       "0        Cornelius  df765d93-621c-437f-99fe-fda9e135f89a\n",
       "1  Gilles Peterson  4c4e3121-4d12-4f7a-a77c-5becd849fb3c"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_G=graph_generator(train_user_top_logs,train_user_top_logs,user_id_profile,track_df,artist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we transform the validation and tests data sets in bipartite graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished for user_001000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntest_gt_user_id_logs = test_user_id_logs[test_user_id_logs['track-id'].isin(track_df['track-id'])]\\ntest_gt_user_id_logs_top = get_only_top(test_user_id_logs,user_id_profile['#id'], n_top = -1)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we select only the music tracks that are in the train set\n",
    "val_user_id_logs = val_user_id_logs[val_user_id_logs['track-id'].isin(track_df['track-id'])]\n",
    "val_user_id_logs_top = get_only_top(val_user_id_logs,user_id_profile['#id'], n_top = -1)\n",
    "\n",
    "test_gt_user_id_logs = test_user_id_logs[test_user_id_logs['track-id'].isin(track_df['track-id'])]\n",
    "test_gt_user_id_logs_top = get_only_top(test_user_id_logs,user_id_profile['#id'], n_top = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished for user_001000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_gt_user_id_logs = test_user_id_logs[test_user_id_logs['track-id'].isin(track_df['track-id'])]\n",
    "test_gt_user_id_logs_top = get_only_top(test_user_id_logs,user_id_profile['#id'], n_top = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#test part :\n",
    "temp_test = get_only_top(val_user_id_logs,user_id_profile['#id'], n_top = 50)\n",
    "temp_test = temp_test.nlargest(10000,'count')\n",
    "temp_test.to_csv('./saved_data/val_user_top_logs.tsv')\"\"\"\n",
    "#Concatenate the train and val sets summing the count for the same track and the same user\n",
    "test_user_id_logs_top = pd.concat([train_user_top_logs, val_user_id_logs_top], ignore_index=True)\n",
    "#sum count column for same track and same user\n",
    "#test_user_id_logs_top.groupby(['userid', 'track-id']).sum('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>userid</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jolene</td>\n",
       "      <td>Cake</td>\n",
       "      <td>user_000949</td>\n",
       "      <td>fa7b9055-3703-473a-8a09-adf2fe031a24</td>\n",
       "      <td>60f0bfa4-8da9-4840-b5fe-23c1fc470f34</td>\n",
       "      <td>1456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Staring At The Sun</td>\n",
       "      <td>Tv On The Radio</td>\n",
       "      <td>user_000949</td>\n",
       "      <td>eb872766-98f6-453d-883f-2ae908a18315</td>\n",
       "      <td>64581a21-566d-4b24-99ae-c5f48b75e660</td>\n",
       "      <td>1409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wings Of Words</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>user_000141</td>\n",
       "      <td>c8524763-e7d7-4225-8a9a-e7b64db5a1e2</td>\n",
       "      <td>2caf09d4-aad9-5f2d-b66d-616f2c2d0e35</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heartbeats</td>\n",
       "      <td>The Knife</td>\n",
       "      <td>user_000949</td>\n",
       "      <td>bf710b71-48e5-4e15-9bd6-96debb2e4e98</td>\n",
       "      <td>db4c9220-df76-4b42-b6f5-8bf52cc80f77</td>\n",
       "      <td>1362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthems For A Seventeen Year Old Girl</td>\n",
       "      <td>Broken Social Scene</td>\n",
       "      <td>user_000949</td>\n",
       "      <td>2eada8f8-056a-4093-bbc2-004909ce743b</td>\n",
       "      <td>91951530-d978-4648-95b1-08b1f49ffba5</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74120</th>\n",
       "      <td>Karma</td>\n",
       "      <td>Kamelot</td>\n",
       "      <td>user_000507</td>\n",
       "      <td>2449300a-6ca7-45da-8102-22789d256475</td>\n",
       "      <td>058c4d03-5244-5c3b-b09c-0ad9cdd3618c</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74121</th>\n",
       "      <td>March Of Mephisto</td>\n",
       "      <td>Kamelot</td>\n",
       "      <td>user_000507</td>\n",
       "      <td>2449300a-6ca7-45da-8102-22789d256475</td>\n",
       "      <td>c55d46c8-20bb-5c22-b07a-bc72ec402caa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74122</th>\n",
       "      <td>Hero In A Dream</td>\n",
       "      <td>Ensiferum</td>\n",
       "      <td>user_000507</td>\n",
       "      <td>6e64cbfa-1a60-450e-81f4-c044c868ab24</td>\n",
       "      <td>3e3d20e3-9226-51ec-9ef6-a9b314076bbb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74123</th>\n",
       "      <td>Wasted Years</td>\n",
       "      <td>Anton Maiden</td>\n",
       "      <td>user_000507</td>\n",
       "      <td>51086134-0896-4c00-b54a-c5c37aeaf2bf</td>\n",
       "      <td>6420dc6c-c1b1-5f42-b0e2-f6207415abd3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74124</th>\n",
       "      <td>All Hell Breaks Loose</td>\n",
       "      <td>Misfits</td>\n",
       "      <td>user_000507</td>\n",
       "      <td>936addc3-91aa-49de-8ec0-0dc186de151f</td>\n",
       "      <td>a0023848-9dbe-57b8-a522-89d141e348ed</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  track-name          artist-name  \\\n",
       "0                                     Jolene                 Cake   \n",
       "1                         Staring At The Sun      Tv On The Radio   \n",
       "2                             Wings Of Words            Chemistry   \n",
       "3                                 Heartbeats            The Knife   \n",
       "4      Anthems For A Seventeen Year Old Girl  Broken Social Scene   \n",
       "...                                      ...                  ...   \n",
       "74120                                  Karma              Kamelot   \n",
       "74121                      March Of Mephisto              Kamelot   \n",
       "74122                        Hero In A Dream            Ensiferum   \n",
       "74123                           Wasted Years         Anton Maiden   \n",
       "74124                  All Hell Breaks Loose              Misfits   \n",
       "\n",
       "            userid                             artist-id  \\\n",
       "0      user_000949  fa7b9055-3703-473a-8a09-adf2fe031a24   \n",
       "1      user_000949  eb872766-98f6-453d-883f-2ae908a18315   \n",
       "2      user_000141  c8524763-e7d7-4225-8a9a-e7b64db5a1e2   \n",
       "3      user_000949  bf710b71-48e5-4e15-9bd6-96debb2e4e98   \n",
       "4      user_000949  2eada8f8-056a-4093-bbc2-004909ce743b   \n",
       "...            ...                                   ...   \n",
       "74120  user_000507  2449300a-6ca7-45da-8102-22789d256475   \n",
       "74121  user_000507  2449300a-6ca7-45da-8102-22789d256475   \n",
       "74122  user_000507  6e64cbfa-1a60-450e-81f4-c044c868ab24   \n",
       "74123  user_000507  51086134-0896-4c00-b54a-c5c37aeaf2bf   \n",
       "74124  user_000507  936addc3-91aa-49de-8ec0-0dc186de151f   \n",
       "\n",
       "                                   track-id   count  \n",
       "0      60f0bfa4-8da9-4840-b5fe-23c1fc470f34  1456.0  \n",
       "1      64581a21-566d-4b24-99ae-c5f48b75e660  1409.0  \n",
       "2      2caf09d4-aad9-5f2d-b66d-616f2c2d0e35  1365.0  \n",
       "3      db4c9220-df76-4b42-b6f5-8bf52cc80f77  1362.0  \n",
       "4      91951530-d978-4648-95b1-08b1f49ffba5  1352.0  \n",
       "...                                     ...     ...  \n",
       "74120  058c4d03-5244-5c3b-b09c-0ad9cdd3618c     1.0  \n",
       "74121  c55d46c8-20bb-5c22-b07a-bc72ec402caa     1.0  \n",
       "74122  3e3d20e3-9226-51ec-9ef6-a9b314076bbb     1.0  \n",
       "74123  6420dc6c-c1b1-5f42-b0e2-f6207415abd3     1.0  \n",
       "74124  a0023848-9dbe-57b8-a522-89d141e348ed     1.0  \n",
       "\n",
       "[74125 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_id_logs_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we create the graph\n",
    "val_G=graph_generator(val_user_id_logs_top,train_user_top_logs,user_id_profile,track_df,artist_df)\n",
    "G_test_gt=graph_generator(test_gt_user_id_logs_top,train_user_top_logs,user_id_profile,track_df,artist_df)\n",
    "G_test=graph_generator(test_user_id_logs_top,train_user_top_logs,user_id_profile,track_df,artist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the graph\n",
    "The graph is too big to be used for training and validation\n",
    "\n",
    "We can remove the low degree nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9359, 9359, 9359, 178556)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_test, train_G,val_G,G_test_gt = remove_low_degree_nodes(G_test,train_G,val_G,G_test_gt)\n",
    "len(G_test.nodes),len(train_G.nodes),len(val_G.nodes),len(G_test_gt.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(686, 686, 686, 169883)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_test, train_G,val_G,G_test_gt = remove_low_artists(G_test,train_G,val_G,G_test_gt)\n",
    "len(G_test.nodes),len(train_G.nodes),len(val_G.nodes),len(G_test_gt.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the methods\n",
    "Pearson coefficient, Bellman ford algorithm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised link prediction\n",
    "\n",
    "ALL THE METHODS ARE TO BE PUT IN A UTIL.PY FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachement(graph, edges=train_G.edges()):\n",
    "    PA = {}\n",
    "    \n",
    "    for edge in edges:\n",
    "        PA[edge] = graph.degree(edge[0]) * graph.degree(edge[1])\n",
    "        \n",
    "    return PA\n",
    "    \n",
    "pa = preferential_attachement(train_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(graph, edges=train_G.edges()):\n",
    "    Jaccard = {}\n",
    "    # Compute Jaccard metric for each non_edge of the graph\n",
    "    \n",
    "    for edge in edges: \n",
    "        inter_size = len(list(nx.common_neighbors(graph, edge[0], edge[1])))\n",
    "        union_size = len(set(graph[edge[0]]) | set(graph[edge[1]]))\n",
    "\n",
    "        if union_size != 0:\n",
    "            Jaccard[edge] = inter_size / union_size\n",
    "        else : \n",
    "            Jaccard[edge] = 0\n",
    "\n",
    "    \n",
    "    return Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamicAdar(graph, edges=train_G.edges()):\n",
    "    AdamicAdar = {}\n",
    "    \n",
    "    for edge in edges: \n",
    "        inter_list = nx.common_neighbors(graph, edge[0], edge[1])\n",
    "        AdamicAdar[edge] = sum( [1/np.log(graph.degree(node)) for node in inter_list] )\n",
    "    \n",
    "    return AdamicAdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the result in the state of the art is bad as the one we obtained here\n",
    "def evaluation(G_train, G_val):\n",
    "    R = G_val.copy()\n",
    "    R.remove_edges_from(e for e in G_val.edges if e in G_train.edges)\n",
    "    gt = R.edges\n",
    "    k = len(gt)\n",
    "    print(k)\n",
    "    print(\"Starting predictions\")\n",
    "    # --- Apply each method defined above and calculate its accuracy ---\n",
    "    methods = ['Jaccard', 'AdamicAdar', 'preferential_attachement']\n",
    "    \n",
    "    # For each method, compute the similarity scores between all non-edges\n",
    "    # Predict k node pairs with highest score \n",
    "    # Compute accuracy wrt edges actually removed \n",
    "    for method in methods: \n",
    "        res = eval(method)(G_train, nx.non_edges(G_train))\n",
    "        print(\"Predicting...\")\n",
    "        pred = sorted(res.items(), key = lambda x:x[1], reverse=True)[:k]\n",
    "        pred = [el[0] for el in pred]\n",
    "        accuracy = len(set(pred).intersection(set(gt))) / k\n",
    "        print(method,\"with an accuracy of \", accuracy,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287\n",
      "Starting predictions\n",
      "Predicting...\n",
      "Jaccard with an accuracy of  0.0 \n",
      "\n",
      "Predicting...\n",
      "AdamicAdar with an accuracy of  0.0 \n",
      "\n",
      "Predicting...\n",
      "preferential_attachement with an accuracy of  0.00777000777000777 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(train_G, val_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervized link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(graph, samples):\n",
    "    \"\"\"\n",
    "    Creates a feature vector for each edge of the graph contained in samples \n",
    "    \"\"\"\n",
    "    feature_vector = []\n",
    "    \n",
    "    # --- Extract manually diverse features relative to each edge contained in samples --- \n",
    "    # Fill in the blanks\n",
    "\n",
    "    # Degree Centrality measure\n",
    "    deg_centrality = nx.degree_centrality(graph)\n",
    "    \n",
    "    # Betweeness centrality measure\n",
    "    betweeness_centrality = nx.betweenness_centrality(graph)\n",
    "\n",
    "    for edge in tqdm(samples):\n",
    "        source_node, target_node = edge[0], edge[1]\n",
    "\n",
    "        # Degree Centrality\n",
    "        source_degree_centrality = deg_centrality[source_node]\n",
    "        target_degree_centrality = deg_centrality[target_node]\n",
    "        \n",
    "        # Betweeness centrality measure \n",
    "        diff_bt = betweeness_centrality[target_node] - betweeness_centrality[source_node]\n",
    "\n",
    "        # Preferential Attachement \n",
    "        pref_attach = list(nx.preferential_attachment(graph, [(source_node, target_node)]))[0][2]\n",
    "\n",
    "        # AdamicAdar\n",
    "        aai = list(nx.adamic_adar_index(graph, [(source_node, target_node)]))[0][2]\n",
    "\n",
    "        # Jaccard\n",
    "        jacard_coeff = list(nx.jaccard_coefficient(graph, [(source_node, target_node)]))[0][2]\n",
    "        \n",
    "        # Create edge feature vector with all metric computed above\n",
    "        feature_vector.append(np.array([source_degree_centrality, target_degree_centrality, \n",
    "                                        diff_bt, pref_attach, aai, jacard_coeff]) ) \n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets try with only detecting for non edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neg_edges_bipartite(G):\n",
    "    top_nodes = set(n for n,d in G.nodes(data=True) if d['bipartite']==0)\n",
    "    low_nodes = set(n for n,d in G.nodes(data=True) if d['bipartite']==1)\n",
    "    adj_matrix = bipartite.biadjacency_matrix(G, row_order=top_nodes, column_order=low_nodes)\n",
    "\n",
    "    negative_edges = []\n",
    "    top = list(top_nodes)\n",
    "    low = list(low_nodes)\n",
    "    for i in tqdm(range(len(top_nodes))):\n",
    "        for j in range(len(low_nodes)):\n",
    "            if adj_matrix[i,j]==0:\n",
    "                negative_edges.append([top[i],low[j]])\n",
    "    return negative_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:01<00:00, 189.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_neg_edges = get_neg_edges_bipartite(train_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges_values(G, edges):\n",
    "    all_positive_edges = G.edges()\n",
    "    output = []\n",
    "    for edge in edges:\n",
    "        if(edge in all_positive_edges): \n",
    "            #output.append(G.edges[edge[0],edge[1]]['weight'])\n",
    "            output.append(1)  \n",
    "        else:\n",
    "            output.append(0)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_links = get_edges_values(val_G, train_neg_edges)\n",
    "new_links.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77352/77352 [00:02<00:00, 27221.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Create feature vector for all edges in training set and test set ---\n",
    "train_features = feature_extractor(train_G, train_neg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_features, train_labels):\n",
    "    \"\"\"\n",
    "    Downstream ML task using edge embeddings to classify them \n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Build the model and train it ---\n",
    "    # Fill in the blanks\n",
    "    clf = RandomForestClassifier(random_state= 1999)\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    #compute accuracy\n",
    "    train_preds=clf.predict(train_features)\n",
    "\n",
    "    print(collections.Counter(np.array(train_preds)))\n",
    "    acc=accuracy_score(train_labels,train_preds)\n",
    "    recall=recall_score(train_labels,train_preds)\n",
    "    precision=precision_score(train_labels,train_preds)\n",
    "\n",
    "    print('Accuracy:',acc, 'Recall:',recall, 'Precision:',precision)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/03/6pjflc5d0qz_wv3xh3hj7rbr0000gn/T/ipykernel_12263/3153672311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRF_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/03/6pjflc5d0qz_wv3xh3hj7rbr0000gn/T/ipykernel_12263/4010582580.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_features, train_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Fill in the blanks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#compute accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RF_model = train(train_features, new_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We test the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Downstream ML task using edge embeddings to classify them \n",
    "    \"\"\"\n",
    "\n",
    "    #compute accuracy\n",
    "    test_preds=model.predict(test_features)\n",
    "\n",
    "    print(collections.Counter(np.array(test_preds)))\n",
    "    acc=accuracy_score(test_labels,test_preds)\n",
    "    recall=recall_score(test_labels,test_preds)\n",
    "    precision=precision_score(test_labels,test_preds)\n",
    "\n",
    "    print('Accuracy:',acc, 'Recall:',recall, 'Precision:',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [00:51<00:00, 18.68it/s]\n",
      "100%|██████████| 2049112/2049112 [03:35<00:00, 9508.51it/s] \n"
     ]
    }
   ],
   "source": [
    "test_neg_edges = get_neg_edges_bipartite(G_test)\n",
    "# --- Create feature vector for all edges in training set and test set ---\n",
    "test_features = feature_extractor(G_test, test_neg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = get_edges_values(G_test_gt, test_neg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10184"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2017932, 1: 31180})\n",
      "Accuracy: 0.9808112001686584 Recall: 0.10035349567949725 Precision: 0.03277742142398974\n"
     ]
    }
   ],
   "source": [
    "predict(RF_model,test_features,test_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
