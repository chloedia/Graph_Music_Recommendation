{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Music recommendation using graphs</h1>\n",
    "<h2>MLNS PROJECT</h2>\n",
    "<h3>Coded by Chloé Daems, Amir Mahmoudi and Anne-Claire Laisney</h3>\n",
    "</center>\n",
    "\n",
    "This is the main notebook to create a benchmark of graph based music recommendation systems inspired by the *Katarya, R., Verma, O.P. Efficient music recommender system using context graph and particle swarm. Multimed Tools Appl 77, 2673–2687 (2018).* [paper](URL 'https://link.springer.com/article/10.1007/s11042-017-4447-x'), using data from the user.getRecentTracks of the [Last.fm](URL 'https://www.last.fm/api/show/user.getRecentTracks') API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.sparse import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "user_id_profile = pd.read_csv('lastfm-dataset-1K/userid-profile.tsv', sep = '\\t')\n",
    "\n",
    "if not exists('lastfm-dataset-1K/user_id_logs_v2.tsv'):\n",
    "    logs_columns = ['userid', 'timestamp', 'artist-id', 'artist-name', 'track-id', 'track-name']\n",
    "    user_id_logs = pd.read_csv('lastfm-dataset-1K/userid-logs.tsv', sep = '\\t', header = None, names =  logs_columns )\n",
    "    user_id_logs = user_id_logs.dropna(subset=['track-name','artist-name', 'artist-id'])\n",
    "else : \n",
    "    user_id_logs = pd.read_csv('lastfm-dataset-1K/user_id_logs_v2.tsv',index_col=0)\n",
    "    user_id_logs = user_id_logs.dropna(subset=['track-name','artist-name', 'artist-id'])\n",
    "    \n",
    "#user_id_logs['timestamp'] = pd.to_datetime(user_id_logs['timestamp'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "user_id_logs['timestamp'] = pd.to_datetime(user_id_logs['timestamp'], format='%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Aug 13, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000002</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Feb 24, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000003</td>\n",
       "      <td>m</td>\n",
       "      <td>22.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oct 30, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000004</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 26, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000005</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Jun 29, 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #id gender   age        country    registered\n",
       "0  user_000001      m   NaN          Japan  Aug 13, 2006\n",
       "1  user_000002      f   NaN           Peru  Feb 24, 2006\n",
       "2  user_000003      m  22.0  United States  Oct 30, 2005\n",
       "3  user_000004      f   NaN            NaN  Apr 26, 2006\n",
       "4  user_000005      m   NaN       Bulgaria  Jun 29, 2006"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>track-id</th>\n",
       "      <th>track-name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 23:08:57</td>\n",
       "      <td>f1b1cf71-bd35-4e99-8624-24a6e15f133a</td>\n",
       "      <td>Deep Dish</td>\n",
       "      <td>7369ec4f-b377-5683-86bd-f02897317103</td>\n",
       "      <td>Fuck Me Im Famous (Pacha Ibiza)-09-28-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:54:10</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>8a0799b1-2f64-5e7b-9436-2228c9d65637</td>\n",
       "      <td>Composition 0919 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:52:04</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>44da66dc-6a34-54de-a4d9-686bc38ede0f</td>\n",
       "      <td>Mc2 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:52</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>e625acbe-1360-528d-8afe-4ad88424e0c0</td>\n",
       "      <td>Hibari (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:11</td>\n",
       "      <td>a7f7df4a-77d8-4f12-8acd-5c60c93f4de8</td>\n",
       "      <td>坂本龍一</td>\n",
       "      <td>fa332ed7-b701-5669-9e8e-0961658cdb43</td>\n",
       "      <td>Mc1 (Live_2009_4_15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid           timestamp                             artist-id  \\\n",
       "0  user_000001 2009-05-04 23:08:57  f1b1cf71-bd35-4e99-8624-24a6e15f133a   \n",
       "1  user_000001 2009-05-04 13:54:10  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "2  user_000001 2009-05-04 13:52:04  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "3  user_000001 2009-05-04 13:42:52  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "4  user_000001 2009-05-04 13:42:11  a7f7df4a-77d8-4f12-8acd-5c60c93f4de8   \n",
       "\n",
       "  artist-name                              track-id  \\\n",
       "0   Deep Dish  7369ec4f-b377-5683-86bd-f02897317103   \n",
       "1        坂本龍一  8a0799b1-2f64-5e7b-9436-2228c9d65637   \n",
       "2        坂本龍一  44da66dc-6a34-54de-a4d9-686bc38ede0f   \n",
       "3        坂本龍一  e625acbe-1360-528d-8afe-4ad88424e0c0   \n",
       "4        坂本龍一  fa332ed7-b701-5669-9e8e-0961658cdb43   \n",
       "\n",
       "                                   track-name  \n",
       "0  Fuck Me Im Famous (Pacha Ibiza)-09-28-2007  \n",
       "1           Composition 0919 (Live_2009_4_15)  \n",
       "2                        Mc2 (Live_2009_4_15)  \n",
       "3                     Hibari (Live_2009_4_15)  \n",
       "4                        Mc1 (Live_2009_4_15)  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are too many track-ids missing, we are going to recreate them using the uuid library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really long : 40 min\n",
    "import tqdm\n",
    "import uuid\n",
    "if not exists('lastfm-dataset-1K/user_id_logs_v2.tsv'):\n",
    "    for idx, row in tqdm.tqdm(user_id_logs.iterrows()):\n",
    "        row['track-id'] = uuid.uuid5(uuid.NAMESPACE_DNS, row['artist-name'] + \",\" + row['track-name'])\n",
    "        row['artist-id'] = uuid.uuid5(uuid.NAMESPACE_DNS, str(row['artist-name']))\n",
    "    #We save the file\n",
    "    user_id_logs.to_csv('lastfm-dataset-1K/user_id_logs_v2.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We create a train and test set**\n",
    "\n",
    "In the test set, we would have only the last month of listening for each users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_logs = user_id_logs[user_id_logs['timestamp'] > datetime.datetime(2009, 4, 4)]\n",
    "train_user_id_logs = user_id_logs[user_id_logs['timestamp'] < datetime.datetime(2009, 4, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : ((17815729, 6) and test shape : ((682269, 6))\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape : ({train_user_id_logs.shape} and test shape : ({test_user_id_logs.shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] > datetime.datetime(2009, 3, 4)]\n",
    "train_user_id_logs = train_user_id_logs[train_user_id_logs['timestamp'] < datetime.datetime(2009, 3, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : ((17217876, 6) and val shape : ((597852, 6))\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape : ({train_user_id_logs.shape} and val shape : ({val_user_id_logs.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's only take the n most listened songs of each users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_top(df_logs,df_profile, n_top):\n",
    "    new_df = pd.DataFrame(columns = ['track-name','artist-name'], dtype= np.str)\n",
    "    for user_id in df_profile.values:\n",
    "        test = df_logs[df_logs['userid']== user_id]\n",
    "        try:\n",
    "            test['count'] = test.groupby(['track-id'])[['track-id']].transform(lambda x: x.count())['track-id']\n",
    "            test = test.sort_values(by = 'count', ascending = False)\n",
    "            test = test.drop('timestamp', axis = 1)\n",
    "            test = test.drop_duplicates()\n",
    "            new_df = pd.concat([new_df, test[:n_top]], ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "        clear_output(wait = True)\n",
    "        print(\"Just finished for\",user_id)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>userid</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Basanov &amp; Vidis ‘Test’</td>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "      <td>7434fb0f-1245-5a58-b343-cca4d0e2c107</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Song</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>4562ff4f-b619-5557-8600-87f6d0d9f348</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Build A Home</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>dcf825de-85a9-5b53-9d2b-a9d574b57470</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track-name              artist-name       userid  \\\n",
       "0                         Music                Cornelius  user_000001   \n",
       "1                           Gum                Cornelius  user_000001   \n",
       "2  Mario Basanov & Vidis ‘Test’          Gilles Peterson  user_000001   \n",
       "3                    Child Song  The Cinematic Orchestra  user_000001   \n",
       "4               To Build A Home  The Cinematic Orchestra  user_000001   \n",
       "\n",
       "                              artist-id                              track-id  \\\n",
       "0  df765d93-621c-437f-99fe-fda9e135f89a  52bef5e2-17b6-5742-b846-09a6b750e857   \n",
       "1  df765d93-621c-437f-99fe-fda9e135f89a  bb9a7981-016d-596e-b17f-ba07a346d2d4   \n",
       "2  4c4e3121-4d12-4f7a-a77c-5becd849fb3c  7434fb0f-1245-5a58-b343-cca4d0e2c107   \n",
       "3  7c158ea8-c0aa-410e-bdc1-20bba9759577  4562ff4f-b619-5557-8600-87f6d0d9f348   \n",
       "4  7c158ea8-c0aa-410e-bdc1-20bba9759577  dcf825de-85a9-5b53-9d2b-a9d574b57470   \n",
       "\n",
       "   count  \n",
       "0   70.0  \n",
       "1   63.0  \n",
       "2   50.0  \n",
       "3   44.0  \n",
       "4   41.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('./saved_data/train_user_top_logs.tsv'):\n",
    "    train_user_top_logs = get_only_top(train_user_id_logs,user_id_profile['#id'], n_top = 50)\n",
    "    train_user_top_logs.to_csv('./saved_data/train_user_top_logs.tsv')\n",
    "\n",
    "else : \n",
    "    train_user_top_logs = pd.read_csv('./saved_data/train_user_top_logs.tsv', index_col=0)\n",
    "\n",
    "train_user_top_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the dataset into a bipartite graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Basanov &amp; Vidis ‘Test’</td>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "      <td>7434fb0f-1245-5a58-b343-cca4d0e2c107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Song</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>4562ff4f-b619-5557-8600-87f6d0d9f348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Build A Home</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>dcf825de-85a9-5b53-9d2b-a9d574b57470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track-name              artist-name  \\\n",
       "0                         Music                Cornelius   \n",
       "1                           Gum                Cornelius   \n",
       "2  Mario Basanov & Vidis ‘Test’          Gilles Peterson   \n",
       "3                    Child Song  The Cinematic Orchestra   \n",
       "4               To Build A Home  The Cinematic Orchestra   \n",
       "\n",
       "                              artist-id                              track-id  \n",
       "0  df765d93-621c-437f-99fe-fda9e135f89a  52bef5e2-17b6-5742-b846-09a6b750e857  \n",
       "1  df765d93-621c-437f-99fe-fda9e135f89a  bb9a7981-016d-596e-b17f-ba07a346d2d4  \n",
       "2  4c4e3121-4d12-4f7a-a77c-5becd849fb3c  7434fb0f-1245-5a58-b343-cca4d0e2c107  \n",
       "3  7c158ea8-c0aa-410e-bdc1-20bba9759577  4562ff4f-b619-5557-8600-87f6d0d9f348  \n",
       "4  7c158ea8-c0aa-410e-bdc1-20bba9759577  dcf825de-85a9-5b53-9d2b-a9d574b57470  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not exists('./saved_data/track_df.tsv'):\n",
    "    track_df = train_user_top_logs.copy()\n",
    "    track_df.drop(['count', 'userid'], axis = 1, inplace=True)\n",
    "    track_df.drop_duplicates('track-id', inplace=True)\n",
    "    track_df.reset_index(drop=True, inplace=True)\n",
    "    track_df.to_csv('./saved_data/track_df.tsv')\n",
    "else : \n",
    "    track_df = pd.read_csv('./saved_data/track_df.tsv', index_col=0)\n",
    "\n",
    "track_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "#We transform the train set into a bipartite graph\n",
    "G= nx.Graph()\n",
    "edges = np.array(train_user_top_logs[['userid', 'track-id']].values)\n",
    "G.add_nodes_from(user_id_profile['#id'], bipartite=0)\n",
    "G.add_nodes_from(track_df['track-id'], bipartite=1)\n",
    "     \n",
    "G.add_edges_from(edges)\n",
    "#weighted graph\n",
    "#G.add_weighted_edges_from(edges)\n",
    "#save the edges\n",
    "nx.write_edgelist(G, \"saved_data/graph_user_tracks_train.el\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished for user_001000\n"
     ]
    }
   ],
   "source": [
    "#We transform the val set into a bipartite graph\n",
    "\n",
    "#First we select only the music tracks that are in the train set\n",
    "val_user_id_logs = val_user_id_logs[val_user_id_logs['track-id'].isin(track_df['track-id'])]\n",
    "val_user_id_logs_top = get_only_top(val_user_id_logs,user_id_profile['#id'], n_top = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track-name</th>\n",
       "      <th>artist-name</th>\n",
       "      <th>userid</th>\n",
       "      <th>artist-id</th>\n",
       "      <th>track-id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>52bef5e2-17b6-5742-b846-09a6b750e857</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gum</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>df765d93-621c-437f-99fe-fda9e135f89a</td>\n",
       "      <td>bb9a7981-016d-596e-b17f-ba07a346d2d4</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Basanov &amp; Vidis ‘Test’</td>\n",
       "      <td>Gilles Peterson</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>4c4e3121-4d12-4f7a-a77c-5becd849fb3c</td>\n",
       "      <td>7434fb0f-1245-5a58-b343-cca4d0e2c107</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Song</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>4562ff4f-b619-5557-8600-87f6d0d9f348</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Build A Home</td>\n",
       "      <td>The Cinematic Orchestra</td>\n",
       "      <td>user_000001</td>\n",
       "      <td>7c158ea8-c0aa-410e-bdc1-20bba9759577</td>\n",
       "      <td>dcf825de-85a9-5b53-9d2b-a9d574b57470</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125862</th>\n",
       "      <td>How To Disappear Completely</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
       "      <td>ccad68b7-c5ad-4f29-b169-2531fbf53f63</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125863</th>\n",
       "      <td>Everything In Its Right Place</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>a74b1b7f-71a5-4011-9441-d0b5e4122711</td>\n",
       "      <td>60bd9d53-01ff-4562-8058-eb44b3940317</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125864</th>\n",
       "      <td>Under The Blacklight</td>\n",
       "      <td>Rilo Kiley</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>eaf6a7ca-105d-4a94-ba02-8c3e4040319a</td>\n",
       "      <td>b912987f-8a21-4c7b-8412-f70ccd6dcd4d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125865</th>\n",
       "      <td>Dreamworld</td>\n",
       "      <td>Rilo Kiley</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>eaf6a7ca-105d-4a94-ba02-8c3e4040319a</td>\n",
       "      <td>d1561c20-50c2-4a48-9f5d-a92572347ddc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125866</th>\n",
       "      <td>Give A Little Love</td>\n",
       "      <td>Rilo Kiley</td>\n",
       "      <td>user_001000</td>\n",
       "      <td>eaf6a7ca-105d-4a94-ba02-8c3e4040319a</td>\n",
       "      <td>c2c88554-8e0b-4ab6-8375-e50ded590b08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116399 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           track-name              artist-name       userid  \\\n",
       "0                               Music                Cornelius  user_000001   \n",
       "1                                 Gum                Cornelius  user_000001   \n",
       "2        Mario Basanov & Vidis ‘Test’          Gilles Peterson  user_000001   \n",
       "3                          Child Song  The Cinematic Orchestra  user_000001   \n",
       "4                     To Build A Home  The Cinematic Orchestra  user_000001   \n",
       "...                               ...                      ...          ...   \n",
       "125862    How To Disappear Completely                Radiohead  user_001000   \n",
       "125863  Everything In Its Right Place                Radiohead  user_001000   \n",
       "125864           Under The Blacklight               Rilo Kiley  user_001000   \n",
       "125865                     Dreamworld               Rilo Kiley  user_001000   \n",
       "125866             Give A Little Love               Rilo Kiley  user_001000   \n",
       "\n",
       "                                   artist-id  \\\n",
       "0       df765d93-621c-437f-99fe-fda9e135f89a   \n",
       "1       df765d93-621c-437f-99fe-fda9e135f89a   \n",
       "2       4c4e3121-4d12-4f7a-a77c-5becd849fb3c   \n",
       "3       7c158ea8-c0aa-410e-bdc1-20bba9759577   \n",
       "4       7c158ea8-c0aa-410e-bdc1-20bba9759577   \n",
       "...                                      ...   \n",
       "125862  a74b1b7f-71a5-4011-9441-d0b5e4122711   \n",
       "125863  a74b1b7f-71a5-4011-9441-d0b5e4122711   \n",
       "125864  eaf6a7ca-105d-4a94-ba02-8c3e4040319a   \n",
       "125865  eaf6a7ca-105d-4a94-ba02-8c3e4040319a   \n",
       "125866  eaf6a7ca-105d-4a94-ba02-8c3e4040319a   \n",
       "\n",
       "                                    track-id  count  \n",
       "0       52bef5e2-17b6-5742-b846-09a6b750e857   70.0  \n",
       "1       bb9a7981-016d-596e-b17f-ba07a346d2d4   63.0  \n",
       "2       7434fb0f-1245-5a58-b343-cca4d0e2c107   50.0  \n",
       "3       4562ff4f-b619-5557-8600-87f6d0d9f348   44.0  \n",
       "4       dcf825de-85a9-5b53-9d2b-a9d574b57470   41.0  \n",
       "...                                      ...    ...  \n",
       "125862  ccad68b7-c5ad-4f29-b169-2531fbf53f63    1.0  \n",
       "125863  60bd9d53-01ff-4562-8058-eb44b3940317    1.0  \n",
       "125864  b912987f-8a21-4c7b-8412-f70ccd6dcd4d    1.0  \n",
       "125865  d1561c20-50c2-4a48-9f5d-a92572347ddc    1.0  \n",
       "125866  c2c88554-8e0b-4ab6-8375-e50ded590b08    1.0  \n",
       "\n",
       "[116399 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate the train and val sets summing the count for the same track and the same user\n",
    "new_val_user_id_logs_top = pd.concat([train_user_top_logs, val_user_id_logs_top], ignore_index=True)\n",
    "#sum count column for same track and same user\n",
    "new_val_user_id_logs_top.drop_duplicates(['userid', 'track-id'], inplace=True)\n",
    "new_val_user_id_logs_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we create the graph\n",
    "\n",
    "G_val = nx.Graph()\n",
    "edges = np.array(new_val_user_id_logs_top[['userid', 'track-id']].values)\n",
    "G.add_nodes_from(user_id_profile['#id'], bipartite=0)\n",
    "G.add_nodes_from(track_df['track-id'], bipartite=1)\n",
    "     \n",
    "G.add_edges_from(edges)\n",
    "#weighted graph\n",
    "#G.add_weighted_edges_from(edges)\n",
    "#save the edges\n",
    "nx.write_edgelist(G, \"saved_data/graph_user_tracks_val.el\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos = nx.spring_layout(G, k=0.3, iterations = 45)\\nnx.draw(G,node_color=color_list, with_labels=False, pos = pos, node_size=50)\\nplt.show()'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"pos = nx.spring_layout(G, k=0.3, iterations = 45)\n",
    "nx.draw(G,node_color=color_list, with_labels=False, pos = pos, node_size=50)\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the methods\n",
    "Pearson coefficient, Bellman ford algorithm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_G = nx.read_edgelist(\"saved_data/graph_user_tracks_train.el\")\n",
    "val_G = nx.read_edgelist(\"saved_data/graph_user_tracks_val.el\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try the methods from TP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised link prediction**\n",
    "\n",
    "ALL THE METHODS ARE TO BE PUT IN A UTIL.PY FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachement(graph, edges=G.edges()):\n",
    "    PA = {}\n",
    "    \n",
    "    for edge in edges:\n",
    "        PA[edge] = graph.degree(edge[0]) * graph.degree(edge[1])\n",
    "        \n",
    "    return PA\n",
    "    \n",
    "pa = preferential_attachement(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(graph, edges=G.edges()):\n",
    "    Jaccard = {}\n",
    "    # Compute Jaccard metric for each non_edge of the graph\n",
    "    \n",
    "    for edge in edges: \n",
    "        inter_size = len(list(nx.common_neighbors(graph, edge[0], edge[1])))\n",
    "        union_size = len(set(graph[edge[0]]) | set(graph[edge[1]]))\n",
    "        Jaccard[edge] = inter_size / union_size\n",
    "    \n",
    "    return Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdamicAdar(graph, edges=G.edges()):\n",
    "    AdamicAdar = {}\n",
    "    \n",
    "    for edge in edges: \n",
    "        inter_list = nx.common_neighbors(graph, edge[0], edge[1])\n",
    "        AdamicAdar[edge] = sum( [1/np.log(graph.degree(node)) for node in inter_list] )\n",
    "    \n",
    "    return AdamicAdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(('user_000791', '830c4338-8ea6-5dad-8deb-f9f903ece418'), 100485), (('user_000791', 'd3395606-9d39-598c-b5a2-0c26a20a85bd'), 97875), (('user_000791', '4d7a8c14-dbd6-539c-8835-2a78837c274f'), 92655), (('user_000544', '830c4338-8ea6-5dad-8deb-f9f903ece418'), 91553), (('user_000791', 'fe561758-dfcc-55f4-a550-514924dcccf5'), 90045), (('user_000544', 'd3395606-9d39-598c-b5a2-0c26a20a85bd'), 89175), (('user_000791', 'e8f0781d-5c0f-5d78-bc63-9f05ba93f6fd'), 80910), (('user_000791', 'cd44f7af-fac5-5770-aea3-162c3471e0f3'), 74385), (('user_000791', '1298d63a-715a-5185-8a21-2e38a765141c'), 73080), (('user_000791', '90744886-c2db-590b-bfb6-50d409cddabf'), 73080)])\n"
     ]
    }
   ],
   "source": [
    "def predict_edges(metric, k):\n",
    "    \n",
    "    # Shuffle randomly entries of dictionnary \n",
    "    l = list(metric.items())\n",
    "    np.random.seed(10) # fix random seed to obtain same random shuffling when repeating experiment\n",
    "    np.random.shuffle(l)\n",
    "    metric = dict(l)\n",
    "\n",
    "    # Retrieve top k value \n",
    "    metric = dict(sorted(metric.items(), key=lambda x:x[1], reverse=True)[:k])\n",
    "    print(metric.items())\n",
    "\n",
    "predict_edges(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68730\n",
      "Starting predictions\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "#1 hour to compute NOT TRIED -- (but the result in the state of the art is bad)\n",
    "def evaluation(G_train, G_val):\n",
    "    R = G_val.copy()\n",
    "    R.remove_edges_from(e for e in G_train.edges if e in G_val.edges)\n",
    "    gt = R.edges\n",
    "    k = len(gt)\n",
    "    print(k)\n",
    "    print(\"Starting predictions\")\n",
    "    # --- Apply each method defined above and calculate its accuracy ---\n",
    "    methods = ['Jaccard', 'AdamicAdar', 'preferential_attachement']\n",
    "    \n",
    "    # For each method, compute the similarity scores between all non-edges\n",
    "    # Predict k node pairs with highest score \n",
    "    # Compute accuracy wrt edges actually removed \n",
    "    for method in methods: \n",
    "        res = eval(method)(G_train, nx.non_edges(G_train))\n",
    "        print(\"predicting 4 real \")\n",
    "        pred = sorted(res.items(), key = lambda x:x[1], reverse=True)[:k]\n",
    "        print(\"I finished predicting\")\n",
    "        pred = [el[0] for el in pred]\n",
    "        #print('pred', pred)\n",
    "        #print('gt',gt)\n",
    "        accuracy = len(set(pred).intersection(set(gt))) / k\n",
    "        print(method, accuracy)\n",
    "\n",
    "evaluation(train_G, val_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervized link prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(graph, train_set_ratio):\n",
    "    \"\"\"\n",
    "    Graph pre-processing step required to perform supervised link prediction\n",
    "    Create training and test sets\n",
    "    \"\"\"\n",
    "        \n",
    "    # --- Step 0: The graph must be connected ---\n",
    "    '''if nx.is_connected(G) is not True:\n",
    "        raise ValueError(\"The graph contains more than one connected component!\")'''\n",
    "       \n",
    "    \n",
    "    # --- Step 1: Generate positive edge samples for testing set ---\n",
    "    residual_g = graph.copy()\n",
    "    test_pos_samples = []\n",
    "      \n",
    "    # Store the shuffled list of current edges of the graph\n",
    "    edges = list(residual_g.edges())\n",
    "    np.random.shuffle(edges)\n",
    "    \n",
    "    # Define number of positive test samples desired\n",
    "    test_set_size = int((1.0 - train_set_ratio) * graph.number_of_edges())\n",
    "    train_set_size = graph.number_of_edges() - test_set_size\n",
    "    num_of_pos_test_samples = 0\n",
    "    \n",
    "    # Remove random edges from the graph, leaving it connected\n",
    "    # Fill in the blanks\n",
    "    for edge in tqdm.tqdm(edges):\n",
    "        \n",
    "        # Remove the edge\n",
    "        residual_g.remove_edge(edge[0], edge[1])\n",
    "        \n",
    "        # Add the removed edge to the positive sample list if the network is still connected\n",
    "        if nx.is_connected(residual_g):\n",
    "            num_of_pos_test_samples += 1\n",
    "            test_pos_samples.append(edge)\n",
    "        # Otherwise, re-add the edge to the network\n",
    "        else: \n",
    "            residual_g.add_edge(edge[0], edge[1])\n",
    "        \n",
    "        # If we have collected enough number of edges for testing set, we can terminate the loop\n",
    "        if num_of_pos_test_samples == test_set_size:\n",
    "            break\n",
    "    \n",
    "    # Check if we have the desired number of positive samples for testing set \n",
    "    if num_of_pos_test_samples != test_set_size:\n",
    "        raise ValueError(\"Enough positive edge samples could not be found!\")\n",
    "\n",
    "        \n",
    "    # --- Step 2: Generate positive edge samples for training set ---\n",
    "    # The remaining edges are simply considered for positive samples of the training set\n",
    "    train_pos_samples = list(residual_g.edges())\n",
    "        \n",
    "        \n",
    "    # --- Step 3: Generate the negative samples for testing and training sets ---\n",
    "    # Fill in the blanks\n",
    "    non_edges = list(nx.non_edges(graph))\n",
    "    np.random.shuffle(non_edges)\n",
    "    \n",
    "    train_neg_samples = non_edges[:train_set_size] \n",
    "    test_neg_samples = non_edges[train_set_size:train_set_size + test_set_size]\n",
    "\n",
    "    \n",
    "    # --- Step 4: Combine sample lists and create corresponding labels ---\n",
    "    # For training set\n",
    "    train_samples = train_pos_samples + train_neg_samples\n",
    "    train_labels = [1 for _ in train_pos_samples] + [0 for _ in train_neg_samples]\n",
    "    # For testing set\n",
    "    test_samples = test_pos_samples + test_neg_samples\n",
    "    test_labels = [1 for _ in test_pos_samples] + [0 for _ in test_neg_samples]\n",
    "    \n",
    "    return residual_g, train_samples, train_labels, test_samples, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(graph, samples):\n",
    "    \"\"\"\n",
    "    Creates a feature vector for each edge of the graph contained in samples \n",
    "    \"\"\"\n",
    "    feature_vector = []\n",
    "    \n",
    "    # --- Extract manually diverse features relative to each edge contained in samples --- \n",
    "    # Fill in the blanks\n",
    "\n",
    "    # Degree Centrality measure\n",
    "    deg_centrality = nx.degree_centrality(graph)\n",
    "    \n",
    "    # Betweeness centrality measure\n",
    "    betweeness_centrality = nx.betweenness_centrality(graph)\n",
    "\n",
    "    for edge in tqdm(samples):\n",
    "        source_node, target_node = edge[0], edge[1]\n",
    "\n",
    "        # Degree Centrality\n",
    "        source_degree_centrality = deg_centrality[source_node]\n",
    "        target_degree_centrality = deg_centrality[target_node]\n",
    "        \n",
    "        # Betweeness centrality measure \n",
    "        diff_bt = betweeness_centrality[target_node] - betweeness_centrality[source_node]\n",
    "\n",
    "        # Preferential Attachement \n",
    "        pref_attach = list(nx.preferential_attachment(graph, [(source_node, target_node)]))[0][2]\n",
    "\n",
    "        # AdamicAdar\n",
    "        aai = list(nx.adamic_adar_index(graph, [(source_node, target_node)]))[0][2]\n",
    "\n",
    "        # Jaccard\n",
    "        jacard_coeff = list(nx.jaccard_coefficient(graph, [(source_node, target_node)]))[0][2]\n",
    "        \n",
    "        # Create edge feature vector with all metric computed above\n",
    "        feature_vector.append(np.array([source_degree_centrality, target_degree_centrality, \n",
    "                                        diff_bt, pref_attach, aai, jacard_coeff]) ) \n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(graph, train_features, test_features, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Downstream ML task using edge embeddings to classify them \n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Build the model and train it ---\n",
    "    # Fill in the blanks\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    train_preds = clf.predict_proba(train_features)[:, 1]\n",
    "    test_preds = clf.predict_proba(test_features)[:, 1]\n",
    "\n",
    "    # --- Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from predictions ---\n",
    "    # Fill in the blanks\n",
    "    fpr, tpr, _ = roc_curve(test_labels, test_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, color='darkred', label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='lightgray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47669/47669 [44:30<00:00, 17.85it/s] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Enough positive edge samples could not be found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/03/6pjflc5d0qz_wv3xh3hj7rbr0000gn/T/ipykernel_85621/3938480985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- Construct the training and testing sets ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresidual_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature extraction ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# --- Create feature vector for all edges in training set and test set ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/03/6pjflc5d0qz_wv3xh3hj7rbr0000gn/T/ipykernel_85621/214970467.py\u001b[0m in \u001b[0;36mgenerate_samples\u001b[0;34m(graph, train_set_ratio)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Check if we have the desired number of positive samples for testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_of_pos_test_samples\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_set_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enough positive edge samples could not be found!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Enough positive edge samples could not be found!"
     ]
    }
   ],
   "source": [
    "# --- Construct the training and testing sets ---\n",
    "residual_g, train_samples, train_labels, test_samples, test_labels = generate_samples(graph=G, train_set_ratio=0.6)\n",
    "print('Feature extraction ...')\n",
    "# --- Create feature vector for all edges in training set and test set ---\n",
    "train_features = feature_extractor(residual_g, train_samples)\n",
    "test_features = feature_extractor(residual_g, test_samples)\n",
    "print('Starting predictions ...')\n",
    "# --- Link prediction ---\n",
    "prediction(residual_g, train_features, test_features, train_labels, test_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
